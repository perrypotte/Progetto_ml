{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moduli necessari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch import nn\n",
    "import pickle\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from os.path import join\n",
    "import os\n",
    "import torch_directml  #Opzionale per usare qualsiasi GPU durante il training\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV creati in percorsi del tipo: ./euro/train/train.csv\n"
     ]
    }
   ],
   "source": [
    "!python util/dataset_maker_regression.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True) #Rieseguire se si apportano modifiche all'env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe per leggere immagini da CSV \n",
    "#### (Richiede CSV ricavati con dataset_maker_regression.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CSVImageDataset(data.Dataset):\n",
    "    def __init__(self, data_root, csv, transform=None):\n",
    "        self.data_root = data_root\n",
    "        self.data = pd.read_csv(csv)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        im_path, im_label = self.data.iloc[i]['Path'], self.data.iloc[i].Label\n",
    "        # il dataset contiene alcune immagini in scala di grigi\n",
    "        # convertiamo tutto in RGB per avere delle immagini consistenti\n",
    "        im = Image.open(join(self.data_root, im_path)).convert('RGB')\n",
    "        \n",
    "        #Per fare eventualmente data augmentation o quelle come toTensor?\n",
    "        if self.transform is not None:\n",
    "            im = self.transform(im)\n",
    "        \n",
    "        return im, im_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcolo media e std per normalizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salva_valori_su_file(valori, file_path):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(valori, file)\n",
    "\n",
    "def leggi_valori_da_file(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        valori = pickle.load(file)\n",
    "    return valori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valori letti dal file: [tensor(0.6095), tensor(0.5478), tensor(0.4684), tensor(0.2324), tensor(0.2478), tensor(0.2655)]\n"
     ]
    }
   ],
   "source": [
    "resolution=640\n",
    "os.makedirs(\"bin\",exist_ok=True)\n",
    "file_path = os.getenv(\"PATH_MEAN_STD\")\n",
    "\n",
    "#******** SE ESISTE UN FILE CON VALORI PRECALCOLATI USA QUELLI********\n",
    "if os.path.exists(file_path):\n",
    "    valori = leggi_valori_da_file(file_path)\n",
    "    print(\"Valori letti dal file:\", valori)\n",
    "    red_mean=valori[0]\n",
    "    green_mean=valori[1]\n",
    "    blue_mean=valori[2]\n",
    "    red_std=valori[3]\n",
    "    green_std=valori[4]\n",
    "    blue_std=valori[5]\n",
    "else:\n",
    "\n",
    "    preprocessing_transform = transforms.Compose([\n",
    "    transforms.Resize((resolution,resolution)),\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    dataset_train=CSVImageDataset(os.getenv(\"PATH_TRAIN_IMAGES\"),os.getenv(\"PATH_TRAIN_CSV\"),transform=preprocessing_transform)\n",
    "    dataset_valid=CSVImageDataset(os.getenv(\"PATH_VALID_IMAGES\"),os.getenv(\"PATH_VALID_CSV\"),transform=preprocessing_transform)\n",
    "    dataset_test=CSVImageDataset(os.getenv(\"PATH_TEST_IMAGES\"),os.getenv(\"PATH_TEST_CSV\"),transform=preprocessing_transform)\n",
    "\n",
    "    red_mean=0\n",
    "    green_mean=0\n",
    "    blue_mean=0\n",
    "    num_pixel=(len(dataset_train)*(resolution)**2)\n",
    "    for image in dataset_train:\n",
    "        red_mean+=image[0][0].sum()# somma di tutti i pixel\n",
    "        green_mean+=image[0][1].sum()# somma di tutti i pixel\n",
    "        blue_mean+=image[0][2].sum()# somma di tutti i pixel\n",
    "    #dividiamo per il numero di immagini molt numero di pixel\n",
    "    red_mean=red_mean/num_pixel\n",
    "    green_mean=green_mean/num_pixel\n",
    "    blue_mean=blue_mean/num_pixel\n",
    "    #deviazione standard\n",
    "    red_std=0\n",
    "    green_std=0\n",
    "    blue_std=0\n",
    "    for image in dataset_train:\n",
    "        red_std+=((image[0][0]-red_mean)**2).sum()\n",
    "        green_std+=((image[0][1]-green_mean)**2).sum()\n",
    "        blue_std+=((image[0][2]-blue_mean)**2).sum()\n",
    "    #sqrt della varianza\n",
    "    red_std=np.sqrt(red_std/num_pixel)\n",
    "    green_std=np.sqrt(green_std/num_pixel)\n",
    "    blue_std=np.sqrt(blue_std/num_pixel)\n",
    "\n",
    "    valori=[red_mean,green_mean,blue_mean,red_std,green_std,blue_std]\n",
    "    salva_valori_su_file(valori, file_path)\n",
    "    print(\"Valori calcolati e salvati:\", valori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparazione del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\perri/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 77.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "model= resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "num_class=1\n",
    "model.fc=nn.Linear(512,num_class,bias=True)\n",
    "#model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Coins: 2\n",
      "torch.Size([3, 640, 640])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.5589)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(640),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([red_mean, green_mean, blue_mean], [red_std, green_std, blue_std])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(640),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([red_mean, green_mean, blue_mean], [red_std, green_std, blue_std])\n",
    "])\n",
    "\n",
    "dataset_train=CSVImageDataset(os.getenv(\"PATH_TRAIN_IMAGES\"),os.getenv(\"PATH_TRAIN_CSV\"),transform=train_transform)\n",
    "dataset_valid=CSVImageDataset(os.getenv(\"PATH_VALID_IMAGES\"),os.getenv(\"PATH_VALID_CSV\"),transform=test_transform)\n",
    "dataset_test=CSVImageDataset(os.getenv(\"PATH_TEST_IMAGES\"),os.getenv(\"PATH_TEST_CSV\"),transform=test_transform)\n",
    "\n",
    "train_loader=(DataLoader(dataset_train,batch_size=16,num_workers=0,shuffle=True))\n",
    "valid_loader=(DataLoader(dataset_valid,batch_size=16,num_workers=0))\n",
    "test_loader=(DataLoader(dataset_test,batch_size=16,num_workers=0))\n",
    "\n",
    "im,lab=dataset_train[150]\n",
    "print('#Coins:',lab)\n",
    "print(im.shape)\n",
    "im.mean()\n",
    "im[0].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe per calcolare la media delle loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageValueMeter():\n",
    "    def init(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.sum = 0\n",
    "        self.num = 0\n",
    "\n",
    "    def add(self, value, num):\n",
    "        self.sum += value*num\n",
    "        self.num += num\n",
    "\n",
    "    def value(self):\n",
    "        try:\n",
    "            return self.sum/self.num\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzione per effettuare il training del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainval(model, train_loader, valid_loader, exp_name='experiment', lr=0.01, epochs=150, momentum=0.99, logdir='logs'):\n",
    "    criterion = nn.MSELoss() #Per regressione usiamo l'MSE loss\n",
    "\n",
    "    #optimizer = SGD(model.parameters(), lr, momentum=momentum)\n",
    "    optimizer=optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Meters\n",
    "    loss_meter = AverageValueMeter()\n",
    "    \n",
    "    # Writer\n",
    "    writer = SummaryWriter(join(logdir, exp_name))\n",
    "    \n",
    "    # Device\n",
    "    #*****DIRECTML*****\n",
    "    # dml=torch_directml.device()\n",
    "    # device = \"cuda\" if torch.cuda.is_available() else  dml\n",
    "    # model.to(device)\n",
    "    #******************\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else  \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    # Definiamo un dizionario contenente i loader di training e test\n",
    "    loader = {\n",
    "        'train': train_loader,\n",
    "        'valid': valid_loader\n",
    "    }\n",
    "\n",
    "    # Inizializziamo il global step (Num. immagini viste)\n",
    "    global_step = 0\n",
    "    # Creiamo la cartella dove salvare il modello se non esiste già\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        print(f\"Epoch {e+1} of {epochs}\")\n",
    "        # iteriamo tra due modalità: train e valid\n",
    "        for mode in ['train', 'valid']:\n",
    "\n",
    "            loss_meter.reset()\n",
    "            model.train() if mode == 'train' else model.eval() # Modalità eval durante la fase di validation\n",
    "\n",
    "            with torch.set_grad_enabled(mode=='train'): # Abilitiamo le operazioni con i gradienti solo durante training\n",
    "                for i, batch in enumerate(loader[mode]):\n",
    "                    x = batch[0].to(device) # Portiamoli sul device corretto\n",
    "                    y = batch[1].to(device)\n",
    "\n",
    "                    y=y.float()\n",
    "\n",
    "                    output = model(x)\n",
    "                    n = x.shape[0] # numero di elementi nel batch\n",
    "                    global_step += n\n",
    "                    l = criterion(output.view(-1), y)\n",
    "                    \n",
    "                    if mode=='train':\n",
    "                        l.backward()\n",
    "                        optimizer.step()\n",
    "                        optimizer.zero_grad()\n",
    "                    \n",
    "                    loss_meter.add(l.item(), n)\n",
    "                    \n",
    "                    #**************DISATTIVATO=>LOGGHIAMO SOLO A FINE EPOCA\n",
    "                    # Loggiamo i risultati iterazione per iterazione solo durante il training\n",
    "                    #if mode=='train':\n",
    "                    #    writer.add_scalar('loss/train', loss_meter.value(), global_step=global_step)\n",
    "            \n",
    "            # Una volta finita l'epoca (sia nel caso di training che test, loggiamo le stime finali)\n",
    "            writer.add_scalar('loss/' + mode, loss_meter.value(), global_step=e+1)\n",
    "            \n",
    "        #Salviamo un checkpoint alla fine di ogni epoca, è possibile continuare il training con questi.\n",
    "        torch.save({\n",
    "            'epoch': e,\n",
    "            'model': model,\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'global_step':global_step\n",
    "            }, './checkpoints/%s-%d.pth'%(exp_name, e+1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m squeezenet_pretrained_regression\u001b[38;5;241m=\u001b[39m\u001b[43mtrainval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexp_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprova\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 55\u001b[0m, in \u001b[0;36mtrainval\u001b[1;34m(model, train_loader, valid_loader, exp_name, lr, epochs, momentum, logdir)\u001b[0m\n\u001b[0;32m     52\u001b[0m l \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), y)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 55\u001b[0m     \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     57\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\perri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\perri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resnet18_regression=trainval(model,train_loader,valid_loader,exp_name='prova',lr=0.0001,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per testare i modelli utilizzare regression_test.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
