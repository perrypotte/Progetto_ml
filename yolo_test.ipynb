{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.46  Python-3.12.4 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2060 SUPER, 8192MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25844392 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\doger\\GitHub\\Progetto_ml\\euro\\test\\labels.cache... 62 images, 3 backgrounds, 0 corrupt: 100%|██████████| 62/62 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:07<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         62        280        0.8      0.738      0.826      0.784\n",
      "                     1          9         14      0.735      0.643       0.81       0.75\n",
      "                    10         13        103      0.842      0.414      0.659      0.597\n",
      "                   100          5         18      0.944      0.942      0.984      0.918\n",
      "                     2         10         12       0.62      0.667      0.705      0.688\n",
      "                    20         13         50      0.372      0.641      0.629      0.597\n",
      "                   200         17         27      0.986      0.963      0.993      0.967\n",
      "                     5          8         31      0.902       0.89      0.942      0.895\n",
      "                    50         23         25          1      0.742      0.887      0.857\n",
      "Speed: 2.2ms preprocess, 18.4ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv(\".env\",override=True)\n",
    "\n",
    "model = YOLO(os.getenv(\"PATH_YOLO_BEST\"))  # load a custom model\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val(data= Path(os.getenv(\"PATH_YAML\")).resolve().as_posix(),split=\"test\")  # no arguments needed, dataset and settings remembered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Matrice di Confusione"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"runs\\detect\\val10\\confusion_matrix_normalized.png\" style=\"width:90%;height:auto;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Curva Precision-Recall"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"runs\\detect\\val10\\PR_curve.png\" style=\"width:90%;height:auto;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, Markdown\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "latest_dir = max( Path(\"./runs/detect\").glob('val*'), key = os.path.getctime )\n",
    "\n",
    "images = {\n",
    "    'confusion_matrix_normalized.png': 'Matrice di Confusione',\n",
    "    'PR_curve.png': 'Curva Precision-Recall'\n",
    "}\n",
    "\n",
    "# Display each image with its title\n",
    "for image_file, title in images.items():\n",
    "    image_path = latest_dir / image_file\n",
    "    if image_path.exists():\n",
    "        display(Markdown(f\"### {title}\"))\n",
    "        display(HTML(f'<img src=\"{image_path}\" style=\"width:{90}%;height:auto;\">'))\n",
    "    else:\n",
    "        print(f\"Image not found: {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**mAP (50-95):** 0.7838  \n",
       "*Mean Average Precision over IoU thresholds 0.50 to 0.95.*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**mAP@50:** 0.8260  \n",
       "*Mean Average Precision at IoU threshold 0.50.*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**mAP@75:** 0.8253  \n",
       "*Mean Average Precision at IoU threshold 0.75.*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Per-category mAP (50-95):**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Category 0: 0.7502"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Category 1: 0.5969"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Category 2: 0.9182"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Category 3: 0.6883"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Category 4: 0.5974"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Category 5: 0.9673"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Category 6: 0.8948"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Category 7: 0.8572"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "def print_metric(name, value, comment):\n",
    "    display(Markdown(f\"**{name}:** {value:.4f}  \\n*{comment}*\"))\n",
    "\n",
    "# Print metrics with comments\n",
    "print_metric(\"mAP (50-95)\", metrics.box.map, \"Mean Average Precision over IoU thresholds 0.50 to 0.95.\")\n",
    "print_metric(\"mAP@50\", metrics.box.map50, \"Mean Average Precision at IoU threshold 0.50.\")\n",
    "print_metric(\"mAP@75\", metrics.box.map75, \"Mean Average Precision at IoU threshold 0.75.\")\n",
    "\n",
    "# Print per-category mAPs\n",
    "display(Markdown(\"**Per-category mAP (50-95):**\"))\n",
    "for i, m in enumerate(metrics.box.maps):\n",
    "    display(Markdown(f\"Category {i}: {m:.4f}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
